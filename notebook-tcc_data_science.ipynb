{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZvwT0GUcY8N"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF\n",
        "!pip install ace_tools_open\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ace_tools_open as tools\n",
        "import fitz  # PyMuPDF para leitura de PDFs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para extrair texto de um arquivo PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as pdf:\n",
        "        for page in pdf:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Função para processar o texto extraído e organizar as informações\n",
        "def process_decision_text(text):\n",
        "    # Inicializar dicionário para armazenar os dados\n",
        "    data = {}\n",
        "\n",
        "    # Extração baseada em palavras-chave\n",
        "    data['Juiz'] = extract_value(text, 'Juiz:')\n",
        "    data['Réu'] = extract_value(text, 'Réu:')\n",
        "    data['Classe Processual'] = extract_value(text, 'Classe Processual:')\n",
        "    data['Comarca'] = extract_value(text, 'Comarca:')\n",
        "    data['Decisão Tomada'] = extract_value(text, 'Decisão:')\n",
        "    data['Pena'] = extract_value(text, 'Pena:')\n",
        "\n",
        "    return data\n",
        "\n",
        "# Função auxiliar para localizar valores no texto com base em palavras-chave\n",
        "def extract_value(text, keyword):\n",
        "    try:\n",
        "        start_idx = text.index(keyword) + len(keyword)\n",
        "        end_idx = text.index('\\n', start_idx)  # Fim da linha\n",
        "        return text[start_idx:end_idx].strip()\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "# Lista de arquivos PDF\n",
        "pdf_files = [\n",
        "    'doc_55662302.pdf',\n",
        "    'doc_61089526.pdf',\n",
        "    'doc_61406539.pdf',\n",
        "    'doc_95012143.pdf',\n",
        "    'doc_108959255.pdf'\n",
        "]\n",
        "\n",
        "# Lista para armazenar os dados extraídos\n",
        "all_data = []\n",
        "\n",
        "# Processar cada PDF\n",
        "for pdf_file in pdf_files:\n",
        "    text = extract_text_from_pdf(pdf_file)\n",
        "    decision_data = process_decision_text(text)\n",
        "    all_data.append(decision_data)\n",
        "\n",
        "# Criar um DataFrame do pandas\n",
        "df = pd.DataFrame(all_data)\n",
        "\n",
        "# Exibir o DataFrame\n",
        "print(df)\n",
        "\n",
        "# Salvar em um arquivo CSV\n",
        "df.to_csv(\"decisoes_judiciais_finais.csv\", index=False)"
      ],
      "metadata": {
        "id": "V2s9R7IEnp9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "df = pd.read_csv('decisoes_judiciais_finais.csv')\n",
        "\n",
        "# Exibir as primeiras linhas do dataset para entender seu formato\n",
        "print(\"Dados originais:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "z1HjWzF8rK_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "df = pd.read_csv('decisoes_judiciais_finais.csv')\n",
        "\n",
        "# Transformações no dataset\n",
        "# 1. Pré Processamento - Deixar apenas as Decisões de culpados, remover as colunas Réu e Decisão e anonimizar o juiz\n",
        "mask = (df['Decisão Tomada'] != 'Culpado')\n",
        "df = df.loc[~mask]\n",
        "\n",
        "#Remoção das colunas\n",
        "df = df.drop(columns=['Réu', 'Decisão Tomada'])\n",
        "\n",
        "#Anonimizar a coluna Juiz\n",
        "df[\"Juiz\"] = df[\"Juiz\"].apply(lambda x: f\"{hash(x) % 10000}\")\n",
        "\n",
        "# 2. Converter a coluna \"Pena\" para valores numéricos (em meses) e categorizando pelos quartis\n",
        "def convert_penalty_to_months(pena):\n",
        "    if pena == \"Nenhuma\":\n",
        "        return 0\n",
        "    elif \"anos\" in pena:\n",
        "        return int(pena.split()[0]) * 12  # Converter anos para meses\n",
        "    elif \"meses\" in pena:\n",
        "        return int(pena.split()[0])  # Manter como meses\n",
        "    return 0\n",
        "\n",
        "df[\"Pena\"] = df[\"Pena\"].apply(convert_penalty_to_months)\n",
        "\n",
        "quartis = df[\"Pena\"].quantile([0.25, 0.5, 0.75]).values\n",
        "\n",
        "# Criando uma nova coluna categórica com base nos quartis\n",
        "df[\"Pena_Categorica\"] = pd.cut(\n",
        "    df[\"Pena\"],\n",
        "    bins=[-1, quartis[0], quartis[1], quartis[2], df[\"Pena\"].max()],\n",
        "    labels=[\"<= 63 Meses\", \"> 63 e <= 108\", \">108 e <= 153\", \"> 153\"]\n",
        ")\n",
        "\n",
        "# Exibindo o DataFrame resultante\n",
        "df[[\"Pena\",\"Pena_Categorica\"]]\n",
        "\n",
        "# 3. Codificar variáveis categóricas usando One Hot Encoder\n",
        "#label_encoders = {}\n",
        "#for column in [\"Juiz\", \"Classe Processual\", \"Comarca\"]:\n",
        "#    le = LabelEncoder()\n",
        "#    df[column] = le.fit_transform(df[column])\n",
        "#    label_encoders[column] = le  # Guardar os encoders para decodificação futura, se necessário\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Evita multicolinearidade\n",
        "encoded_vars = encoder.fit_transform(df[[\"Juiz\", \"Comarca\", \"Classe Processual\"]])\n",
        "\n",
        "# Criando um DataFrame com as variáveis codificadas\n",
        "encoded_columns = encoder.get_feature_names_out([\"Juiz\", \"Comarca\", \"Classe Processual\"])\n",
        "df_encoded = pd.DataFrame(encoded_vars, columns=encoded_columns)\n",
        "\n",
        "#df_encoded\n",
        "\n",
        "# Concatenando as novas variáveis ao DataFrame original e removendo as colunas antigas\n",
        "df = pd.concat([df.drop(columns=[\"Juiz\", \"Comarca\",\"Classe Processual\"]).reset_index(drop=True), df_encoded.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Exibindo as primeiras linhas do DataFrame transformado\n",
        "tools.display_dataframe_to_user(name=\"Dataset com One-Hot Encoding\", dataframe=df)\n",
        "\n",
        "# Salvar o dataset transformado para uso posterior\n",
        "df.to_csv('decisoes_judiciais_anonimizadas.csv', index=False)"
      ],
      "metadata": {
        "id": "8hjC3n-JdvXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando Random Forest e visualizando a importância das variáveis\n",
        "columns = list(df.columns)\n",
        "columns.remove(\"Pena\")\n",
        "columns.remove(\"Pena_Categorica\")\n",
        "\n",
        "# Definindo os dados de entrada (features) e saída (target)\n",
        "x = df[columns]\n",
        "y = df[\"Pena_Categorica\"]\n",
        "\n",
        "# Dividindo os dados em conjunto de treinamento e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Criando o modelo Random Forest\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42, bootstrap=True, max_depth=None)\n",
        "random_forest_model.fit(x_train, y_train)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred = random_forest_model.predict(x_test)\n",
        "y_test\n",
        "\n",
        "# Avaliando a acurácia\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acurácia do modelo: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Extraindo importância das variáveis\n",
        "feature_importances = random_forest_model.feature_importances_\n",
        "features = x.columns\n",
        "\n",
        "importances_df = pd.DataFrame({\"Variavel\": features, \"Importancia\": feature_importances*100}).sort_values(by=\"Importancia\", ascending=False)\n",
        "importances_df"
      ],
      "metadata": {
        "id": "vmsNJCufrLZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importancia das variáveis agregadas\n",
        "print(\"Importancia da Comarca\",importances_df.query('Variavel.str.contains(\"Comarca\")', engine='python').sum())\n",
        "print(\"Importancia do Juiz\",importances_df.query('Variavel.str.contains(\"Juiz\")', engine='python').sum())\n",
        "print(\"Importancia da Classe Processual\",importances_df.query('Variavel.str.contains(\"Classe Processual\")', engine='python').sum())"
      ],
      "metadata": {
        "id": "rc8mfSIRgZUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando a importância das variáveis\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importances_df['Variavel'], importances_df['Importancia'], color='blue')\n",
        "plt.xlabel('Importância')\n",
        "plt.title('Importância da Variável')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mZuX5b6dye76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar as árvores de decisão (apenas as primeiras 3 para demonstração)\n",
        "plt.figure(figsize=(100,100))\n",
        "for i in range(min(3, len(random_forest_model.estimators_))):  # Limitar a 3 árvores ou o número de árvores no modelo\n",
        "    plt.subplot(1, min(3, len(random_forest_model.estimators_)), i + 1)\n",
        "    plot_tree(random_forest_model.estimators_[i], feature_names=features, filled=True, rounded=True, class_names=np.unique(y).astype(str))\n",
        "    plt.title(f\"Árvore {i+1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EOld3_kBtqif"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
